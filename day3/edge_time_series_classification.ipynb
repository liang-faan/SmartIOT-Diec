{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "edge_time_series_classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lisaong/diec/blob/master/day3/edge_time_series_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_4tTEupk1eV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Edge Device Model Deployment\n",
        "\n",
        "In this notebook, we will train a deep learning model and deploy it to the edge.\n",
        "\n",
        "1. Train model using Keras\n",
        "2. Convert to compressed floating point version using Tensorflow Lite\n",
        "3. Deploy on Raspberry Pi\n",
        "\n",
        "We will use this dataset, which is gathered from a smart factory in Germany: https://www.kaggle.com/inIT-OWL/versatileproductionsystem\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQsJxbFhGkwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smHIl430lswe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "sns.set(style='whitegrid')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9g7zOtylkXH",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Load the dataset from our github repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9TTNMJZlwVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl https://raw.githubusercontent.com/lisaong/diec/master/data/versatileproductionsystem.zip --output data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3yvFuQRl9HY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -o data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W1mQD8mmGZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read one of the data files\n",
        "df = pd.read_csv('./Filling_ALL.module.csv', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4L4UWkHnK3q",
        "colab_type": "text"
      },
      "source": [
        "## Task Definition\n",
        "\n",
        "A common factory monitoring scenario is to predict a target based on past history.\n",
        "\n",
        "For the purposes of this workshop, let's try to predict the value of 'I_BottlesReserveAvailable', using last 10 values of each feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVGhZWp0mSco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Target\n",
        "target = 'I_BottlesReserveAvailable'\n",
        "\n",
        "df[target].plot();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vJxiO4oBWv79",
        "colab": {}
      },
      "source": [
        "# check for balanced classes\n",
        "df[target].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSPmAh6OZO24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop some columns that the target is derived from (otherwise we are cheating)\n",
        "df.drop(['BottlesAvailable', 'BottlesNotUsed', 'I_BottleStorageFull'], axis=1, inplace=True)\n",
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-PJjLMPLNKV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdl1Wtt7w526",
        "colab_type": "text"
      },
      "source": [
        "## Reserve for testing\n",
        "\n",
        "Reserve the some values for testing on the Raspberry Pi.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFR6DTl5xDwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_size = 100\n",
        "\n",
        "df_train = df.iloc[:-test_size]\n",
        "df_test = df.iloc[-test_size:]\n",
        "\n",
        "df_train.shape, df_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTFHCNClxGda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save input numpy arrays for later use\n",
        "pickle.dump(df_train.loc[:, df_train.columns != target].values,\n",
        "            open('./X_train.pkl', 'wb'))\n",
        "\n",
        "pickle.dump(df_test.loc[:, df_test.columns != target].values,\n",
        "            open('./X_test.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi1EqEi0p_Ig",
        "colab_type": "text"
      },
      "source": [
        "## Feature Selection\n",
        "\n",
        "First, some basic feature selection: Filter out columns that don't change very much (low variance). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJl8kbsfnc0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Candidate features\n",
        "\n",
        "candidates = df_train.columns[df_train.columns != target]\n",
        "candidates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6RmjiHnosf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply variance threshold of 0.1\n",
        "vt = VarianceThreshold(threshold=0.1)\n",
        "vt.fit(df_train[candidates])\n",
        "\n",
        "# filtered out features\n",
        "features = candidates[vt.get_support()]\n",
        "features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I450WKGxp8iK",
        "colab_type": "text"
      },
      "source": [
        "## Scaling\n",
        "\n",
        "Next, scale the features so that we can speed up training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxqF8I-Ns2xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "feature_values = feature_scaler.fit_transform(df_train[features])\n",
        "feature_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwfGR-uttMFp",
        "colab_type": "text"
      },
      "source": [
        "## Time Series Windowing\n",
        "\n",
        "Next, convert the time series so that each entry contains a series of timesteps.\n",
        "\n",
        "Before: rows, features\n",
        "\n",
        "After: rows, timesteps, features\n",
        "\n",
        "Note that some rows will be removed because we are taking a window of values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQcRa6rhuAT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "timesteps = 10\n",
        "\n",
        "print(feature_values.shape) # (rows, features)\n",
        "\n",
        "rolling_indexes = [(range(i, i+timesteps))\n",
        "                   for i in range(feature_values.shape[0]-timesteps)]\n",
        "\n",
        "X_sequence = np.take(feature_values, rolling_indexes, axis=0)\n",
        "X_sequence.shape # (rows, timesteps, features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S6D2yR2u_Jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shift y down by 1 value so that we are predicting the future\n",
        "# make sure y is the same length as X_sequence\n",
        "\n",
        "print(df[target].shape)\n",
        "y = df[target][1:X_sequence.shape[0]+1].values\n",
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X6W5eIGvqvu",
        "colab_type": "text"
      },
      "source": [
        "## Train model\n",
        "\n",
        "We will train a very simple 1D convolutional model to try to predict y from X_sequence. \n",
        "\n",
        "To recap:\n",
        "\n",
        "- X_sequence (rows, timesteps, features): each scaled feature at [t-9] ... [t]\n",
        "- y (rows): target[t+1]\n",
        "\n",
        "The convolutional 1D layer will look at windows of timesteps, one feature at a time. Here's a more detailed reference on it for time series data: https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/\n",
        "\n",
        "\n",
        "Note: we can also train an LSTM model, but currently Tensorflow Lite with Keras does not support it nicely (yet): https://github.com/tensorflow/tensorflow/issues/30864"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJNTF_O0wwWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_sequence, y, test_size=0.1,\n",
        "                                                  stratify=y)\n",
        "\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQFDJF2ZzIgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# input_shape=(timesteps, features)\n",
        "model.add(Conv1D(64, kernel_size=3,\n",
        "                 input_shape=(X_train.shape[1], X_train.shape[2]),\n",
        "                 activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBg-PTRMzeRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y9pngt3znUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mc = ModelCheckpoint('./cnn.h5', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz_DdKvCzwzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_val, y_val), callbacks=[mc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbuJgmewz8im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "ax.plot(history.history['loss'], label='train')\n",
        "ax.plot(history.history['val_loss'], label='val')\n",
        "ax.legend()\n",
        "ax.set_title('Learning curve')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tahIDN_WDvQM",
        "colab_type": "text"
      },
      "source": [
        "### Predictions\n",
        "\n",
        "We'll test the model by getting predictions for our test data.\n",
        "\n",
        "The steps followed here will be repeated on the Raspberry Pi, so we want to make sure these are repeatable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiJUdJpSDlNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test_X = df_test.loc[:, df_test.columns != target]\n",
        "df_test_y = df_test[[target]]\n",
        "\n",
        "df_test_X.shape, df_test_y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USjKp883EOqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select features\n",
        "test_X = vt.transform(df_test_X)\n",
        "\n",
        "# scale\n",
        "test_X_scaled = feature_scaler.transform(test_X)\n",
        "\n",
        "# create windowed\n",
        "rolling_indexes = [(range(i, i+timesteps))\n",
        "                   for i in range(test_X_scaled.shape[0]-timesteps)]\n",
        "\n",
        "test_X_sequence = np.take(test_X_scaled, rolling_indexes, axis=0)\n",
        "\n",
        "print(test_X_sequence.shape) # (rows, timesteps, features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGz6tdoxJHcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shift y down by 1 value so that we are predicting the future\n",
        "# make sure y is the same length as test_X_sequence\n",
        "\n",
        "test_y = df_test_y[1:test_X_sequence.shape[0]+1] \n",
        "print(test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4W4u4A7EvG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict by loading the checkpointed model with the lowest validation loss\n",
        "best_model = load_model('./cnn.h5')\n",
        "pred = best_model.predict_classes(test_X_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTooEXjjJrMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# score\n",
        "print(classification_report(test_y, pred))\n",
        "print(confusion_matrix(test_y, pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y9NVNM1cOTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try to predict some class 0 values using validation set\n",
        "\n",
        "pred_val = model.predict_classes(X_val)\n",
        "\n",
        "print(classification_report(y_val, pred_val))\n",
        "print(confusion_matrix(y_val, pred_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVGUHHVw4m65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Uk91yIeRqX",
        "colab_type": "text"
      },
      "source": [
        "## Deployment\n",
        "\n",
        "1. Save pre-processors\n",
        "2. Convert to Tensorflow Lite: https://www.tensorflow.org/lite/convert#from_model_training_to_device_deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ATL_6He5GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save preprocessors, create a dictionary so that everything in 1 place\n",
        "\n",
        "preprocessors = {\n",
        "    'variance_threshold' : vt,\n",
        "    'feature_scaler' : feature_scaler   \n",
        "}\n",
        "\n",
        "pickle.dump(preprocessors, open('./preprocessors.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-cvueJofSG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to Tensorflow lite\n",
        "saved_model = tf.keras.models.load_model('./cnn.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(saved_model)\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/lite/Optimize\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY] \n",
        "\n",
        "tflite_model = converter.convert()\n",
        "with open('./cnn.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiitATTdskPd",
        "colab_type": "text"
      },
      "source": [
        "### Testing TensorFlow Lite Inference\n",
        "\n",
        "https://www.tensorflow.org/lite/guide/inference#running_a_model\n",
        "\n",
        "Before running inference on a Raspberry Pi, it is easier to write code and test out the inference on a PC or Google Cloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDidAr3cueqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the code we will run on the Raspberry Pi\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def load_test_data(data_filename, preprocessors_filename):\n",
        "  timesteps = 10\n",
        "\n",
        "  # Load test data and process it\n",
        "  test_array = pickle.load(open(data_filename, 'rb'))\n",
        "\n",
        "  preprocessors = pickle.load(open(preprocessors_filename, 'rb'))\n",
        "  vt = preprocessors['variance_threshold']\n",
        "  feature_scaler = preprocessors['feature_scaler']\n",
        "\n",
        "  # select features\n",
        "  test_X = vt.transform(test_array)\n",
        "\n",
        "  # scale\n",
        "  test_X_scaled = feature_scaler.transform(test_X)\n",
        "\n",
        "  # create windowed\n",
        "  rolling_indexes = [(range(i, i+timesteps))\n",
        "                     for i in range(test_X_scaled.shape[0]-timesteps)]\n",
        "\n",
        "  test_X_sequence = np.take(test_X_scaled, rolling_indexes, axis=0)\n",
        "  print(test_X_sequence.shape) # (rows, timesteps, features)\n",
        "    \n",
        "  return test_X_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UVR01Qmwqoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = load_test_data('./X_test.pkl', './preprocessors.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mArG7XJat0Pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model_path, test_data):\n",
        "  # Load TFLite model and allocate tensors.\n",
        "  interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  # Get input and output tensors.\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "\n",
        "  # Test model on input data.\n",
        "  input_shape = input_details[0]['shape']\n",
        "\n",
        "  # Loop through each row of test_data and perform inference\n",
        "  for i in range(test_data.shape[0]):\n",
        "\n",
        "    # add batch dimension\n",
        "    input_data = np.expand_dims(test_data[i], axis=0).astype('float32')\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # The function `get_tensor()` returns a copy of the tensor data.\n",
        "    # Use `tensor()` in order to get a pointer to the tensor.\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    print(output_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shAXE78UKseL",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 1: Testing the compressed model\n",
        "<p>\n",
        "<font color=\"red\">\n",
        "Update the cell below to get predictions from N randomly chosen samples, using the Tensorflow Lite version of the model.\n",
        "</font>\n",
        "</p>\n",
        "<p>\n",
        "<font color=\"green\">\n",
        "Submission:\n",
        "<ol>\n",
        "<li type='a'>Paste the updated code into the submission worksheet</li>\n",
        "<li type='a'>Paste predictions into the submission worksheet</li>\n",
        "</ol>\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F__0o3I6uLtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exercise: test out your compressed tensorflow lite model to get\n",
        "# predictions from randomly selected samples before deploying to the Edge device.\n",
        "#\n",
        "# Hint1: you may use the helper function above to get a prediction.\n",
        "# Hint2: you may use the following code to get a random selection of samples\n",
        "# N = <pick_a_number>\n",
        "# random_index = np.random.choice(range(len(X_test)), N)\n",
        "#\n",
        "\n",
        "X_test = load_test_data('./X_test.pkl', './preprocessors.pkl')\n",
        "\n",
        "#\n",
        "# ADD YOUR CODE BELOW\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}